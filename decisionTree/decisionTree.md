# 				决策树（decision tree）

## 1、原理

​		训练决策树，依次试用每一种特征进行分类，找到信息熵减小最多的特征当做这一次分类使用的特征。然后再次重复上一步骤找到信息熵减小最多（信息增益）的特征当做这一次分类使用的特征，直到所有的了所有的数据都为某一类或者所有特征都使用了（返回节点数最多的类别）

​		信息熵：数据复杂度越小信息熵越小。

​		信息熵公式：H=-∑(P(i)*log2［P(i)］)(i=1,2,3…)

